
## Honours Research Project Proposal

Student: Vasena Jayamanna

Supervisors: Dr. Michael Domaratzki, Dr. Eduardo Taboada


### Introduction

We will be developing a tool for active reporting on SARS-CoV-2 phylogenetic analysis and associated metadata, using the existing EpiQuant analysis framework [[3]](#3). Within this reporting tool we plan to compare clusters of cases across points in time while considering a variety of different factors. My project involves development of a module in which we detect and report on any clusters with a significant increase in size from one time point to the next. While detection of expanding clusters is the focus, I will also use this information as "label data" to attempt prediction of clusters that can be expected to increase in size. In other words, prediction of population prevalence at a secondary time point, using genome data and associated metadata at a primary time point. 

### Background preparation

Data available from open source data repositories such as Nextstrain [[2]](#2) and GISAID [[1]](#1) will be used for analysis. Relevant genomic/phylogenetic data and associated metadata will be collected and processed. We will use the phylogenetic data to extract clusters at significant similarity thresholds. The metadata will be cleaned for use as input into the expanding cluster detection module as well as for the machine learning model in prevalence prediction. Research into appropriate learning algorithms will be done as a starting point of analysis.

### Related work

The EpiQuant model is based on the use of epidemiologic cluster cohesion (ECC), which is a “measure of … homogeneity of isolates within a subtyping cluster” [[4]](#4). Isolates within clusters with high ECC values have epidemiologic profiles with high similarity [[3]](#3). We plan to compute the ECC of clusters generated at various thresholds and under different parameter settings and this analysis will form the core of the reporting tool. I will be responsible for developing a module for monitoring cluster prevalence and cluster expansion which will also include a machine learning component for predicting clusters likely to expand. 

### Problem statement

Rapid reporting on genomic information on COVID-19 suitable for public health officials and front-line epidemiologists is needed. A COVID-19 reporting tool is being developed that will require a module for monitoring cluster prevalence over time and detecting cluster expansion. An additional feature of great interest would be the ability to prospectively predict clusters likely to undergo future expansion. In addition to developing the tools for basic cluster prevalence monitoring, I will develop a machine learning model that can predict SARS-CoV-2 cluster prevalence at a secondary time point, given cluster prevalence, metadata and phylogenetic information at the primary time points.

### Methodology

  - Develop method for comparing the cluster size and cluster composition between time points.
    - **Week 1:** Data at three separate time points have been sampled from the available NextStrain repository. This resulted in information for 3692 strains on April 15th, 4690 strains on May 17th, and 4382 strains on June 4th of this year. Using clusters extracted by our team from the phylogenetic Newick trees, I compared the data across the three time points, identifying recurring strains (that were found at more than one time point) and new strains (only found at one of the three time points). Given an isolate, time point, and threshold, the size of the corresponding cluster is returned, and in this manner I can compare cluster sizing and composition across the relevant parameters while accounting for strains added or removed between time points. This is still in the preliminary stage of method development. 
    - *Plan for Week 2: Prepare a draft of the module that identifies clusters that increase significantly in size (with a user input for "significant change", for now). It should output the sizes, membership, and a simple plot or two for visualizing the change in cluster size.*
  - Develop reporting module that outputs cluster sizes, cluster membership, difference in cluster size between time-points.
    - **Week 2:** Designed a framework for the cluster detection module, with key components to guide further development. I’m initially using rmarkdown to generate an html report as output and may use a different method or platform as the project develops. So far, it reads in threshold data for two timepoints from a user. Then the cluster sizes are calculated, while keeping track of the isolates within each cluster (for all heights at both timepoints). Using the isolates to track cluster membership, the sizes of a cluster at one timepoint versus the next is noted (for a particular height). Clusters that increase in size from time point 1 (TP1) to time point 2 (TP2) are assigned an indicative label, as are clusters that do not change in size or are instead found in different (smaller) clusters. There are various datatables with all of this information (at different levels of detail) for the user to see. 
    - *Plan for Week 3: Validate the steps leading up to this point and be able to explain and/or providing clear supporting reasoning. I need to verify that the cluster matching is not missing anything and add a method to keep track of both recurring isolates and those that are found at only one timepoint. I also need to do some analysis looking at the counts of clusters that “increase” or “decrease” in size, and investigate statistical methods that might be helpful for identifying “significant” cluster size change.*
    - **Week 3:** Reviewed cluster matching methods used, and I plan on asking another member of the team to review my work when I am satisfied with the statistical analysis section of the module. I have added a few more components to the module as tables and plots to better illustrate what we are working with on a cluster change detection level. This includes sections that clearly indicate which isolates are found in one or both of the time point data sets, outputs on cluster labelling, and user input (on a basic level) for indicating what kinds of cluster size change can be considered "significant". I have spent some time on reviewing the statistical testing process and different kinds of tests that might help identify a level of cluster size change that is statistically significant, and that we can use as a default, with an indicator to the user. 
    - *Plan for Week 4: More review of statistical testing, to make sure I am not missing any steps. Then completing the statistical process (I am only partway through, at this point) to the point that we may be able to conclusively reject or accept the null hypothesis, that a cluster size change of > x is not notable. Adding visuals and explanation to demonstrate how the conclusion was reached will be necessary as well.*
  - Analyze example data to generate labelled clusters at Time 1 that underwent significant cluster expansion by Time 2. 
    - **Week 4:** Went through a variety of different statistical analysis methods to identify the probability distribution that best fits the change in cluster size, at randomly selected thresholds, to identify what kind of change can be considered out of the ordinary, or "significant". I would like to reiterate that in this part of the process I am attempting to fine-tune the labeling of cluster size change, so that change considered statistically significant will be appropriately labeled. Randomly selected thresholds at this point because this results in a snapshot of cluster size change that can be clearly modeled and compared, to make developing the method more streamlined. Using a series of histograms (frequency plots of size change), density plots, and quantile-quantile plots, I drew up many visuals for at-a-glance comparison, and used AICs to identify a candidate distribution. Then, using R to experiment with different tools for goodness-of-fit tests, I eventually managed to narrow down the result to a potential distribution using a package for distribution fitting with ["Generalized Additive Models for Location Scale and Shape"](https://cran.r-project.org/web/packages/gamlss/gamlss.pdf).
    - *Plan for Week 5: More analysis will be necessary, to be sure there is supporting evidence for the candidate distribution. I would also like to do enough research to be sure there is not a simpler model that might fit better. And high up on the priority list is to organize and edit for clarity the components of the module that I have worked on so far, so that they can be shared for team review.*
    - **Week 5:** Organized and compiled a set of reports in markdown document format with html outputs for team review. Discussed work so far with supervisor, to identify problem areas of workflow and improvements or changes that needed to be made. Results of discussion: going to put together some synthetic data as well as run the framework on a few different datasets, as peculiarities of the datasets I was using (as samples for development) were overpowering and tricky to deal with. Also, I need to refocus to be sure the framework is being designed properly and that I do not lose sight of the end goals. More frequent review will be helpful. Another issue was that of differences in clustering between time points making inter-threshold comparison something that needs to be verified.
    - *Plan for Week 6: Going to use Adjusted Wallace coefficients to verify that the "same" threshold between time points, results in clusters similar enough to be compared. If this turns out to be problematic, an alternative method of comparison will be necessary, perhaps by using stable heights with the most similar cluster groupings or some other method. This will need to be dealt with first before returning to the probability distribution question.*
    - **Week 6:** As the modeling framework is the focus of this project, I was provided with some alternative datasets by my supervisor (on Campylobacter data curated by the lab) as we can verify that isolates present at time point 1 were also present in the time point 2 dataset. This was not necessarily the case for the Covid. datasets I had been working with; we believe some genomes may have been removed from the latter time points for curation purposes. By working with data we can verify, we can focus less on data curation and more on the tool development. I also prepared a method for outputting synthetic data modeled after the distribution of clusters in the new dataset, and plan to check the workflow on a variety of data to check for problems. I made adjustments where necessary to best showcase my work so far with the new (real) data, and presented to the team to get viewpoints on next steps, as well as for me to practice explaining the workflow (to check that it makes sense when explained to a third party). 
    - *Plan for Week 7: We came to the conclusion of a more direct way forward. So far, the comparison has been done comparing clusters at corresponding heights at the distinct timepoints. These heights were part and parcel of the dataset, but it would be more effective to compare a cluster y at time point 2 to its direct predecessor at time point 1, tracking back through the thresholds until we arrive at a cluster x containing all of the cluster y isolates except for the novel genomes. This is in response to how the data is clustered separately at the two time points, and how just the addition of a single genome can affect clustering results. My inexperience in the biology of clustering may have slowed our progress in this area, as I was using a more complicated way to get to our results. I will make the necessary adjustments and run the tool on the synthetic data as well before reporting back to my supervisor to verify next steps.* 
  - Identify fields with enough information to be potential input in a machine learning model, pinpoint preferred format of output (type of classification). 
  - Select type(s) of model(s) that are appropriate for the problem and set initial parameter values.
  - Split the data into training and test data sets. Train the data.
  - Evaluate the results and adjust parameters (or model choice) as required. We will repeat the training and evaluation until results are as satisfactory as possible.
  - Test the model on the test data and analyze the results, comparing test and training error as a check.

### Infrastructure required

The sequence data and metadata are readily available from public repositories, and we have sufficient independent computing resources via personal workstations at the National Microbiology Lab and access to laboratory data servers.

### Outcomes

  1. A module in the reporting tool for cluster prevalence and cluster expansion detection given independent time points and corresponding data, or
  2. A learning algorithm that can predict population prevalence for significant clusters at the given time points, or 
  3. A conclusion on features for which we need more data before the model can perform effectively;  identification of potential influencing factors in cluster expansion over time.

### References

<a id="1">[1]</a> S. Elbe and G Buckland-Merrett.  ”Data, disease and diplomacy:  GISAID’s innovative contribution toglobal health.”.Global Challenges, 1:33–46, 2017.

<a id="2">[2]</a> Hadfield et al. ”Nextstrain: real-time tracking of pathogen evolution.”.Bioinformatics, 34(23):4121–4123,01 December 2018.

<a id="3">[3]</a> Benjamin M et al Hetman.  ”The EpiQuant Framework for Computing Epidemiological Concordance ofMicrobial Subtyping Data.”.Journal of Clinical Microbiology, 55(5):1334–1349, 2017.

<a id="4">[4]</a> Eduardo Taboada.  ”The Campy-COVID project:  applying the EpiQuant framework to facilitate large-scale reporting on SARS-CoV-2 WGS data.”.  PowerPoint presentation, April 2020.
